---
permalink: /
title: "Ke Jiang (蒋珂)"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

News
======
 - 8 November, 2025: Our paper [Variational OOD State Correction for Offline Reinforcement Learning](https://arxiv.org/abs/2505.00503) has been accepted by *The 40th Annual AAAI Conference on Artificial Intelligence (AAAI)*, Main Technical Track, 2026.
 - 29 October, 2025: Our paper [Beyond Non-Expert Demonstrations: Outcome-Driven Action Constraint for Offline Reinforcement Learning](https://arxiv.org/abs/2504.01719) has been accepted by *Pattern Recognition*, Elsevier, as a regular paper.
 - 29 September, 2025: Our paper [Towards Reliable Offline Reinforcement Learning via Lyapunov Uncertainty Control](https://doi.org/10.1109/TNNLS.2025.3616159) has been accepted by *IEEE Transactions on Neural Networks and Learning Systems* as a regular paper.
 - From 14 April, 2025: I started working as a visiting researcher at [Machine Learning & Systems Laboratory](https://mls.ist.osaka-u.ac.jp/en/member.html), [Graduate School of Information Science and Technology](https://www.ist.osaka-u.ac.jp/english/). My advisor here is [Professor Yoshinobu Kawahara](https://mls.ist.osaka-u.ac.jp/en/~kawahara/).
 - 21 March, 2025: Our paper [RoGA: Towards Generalizable Deepfake Detection through Robust Gradient Alignment](https://arxiv.org/abs/2505.20653) has been accepted by *IEEE International Conference on Multimedia & Expo (ICME)* 2025 <span style="color:red">(Oral)</span>.
 - 25 September, 2023: Our paper [Recovering from out-of-sample states via inverse dynamics in offline reinforcement learning](https://proceedings.neurips.cc/paper_files/paper/2023/file/7a0f7e9d9b42b26e5bfc9ba4c6e5287c-Paper-Conference.pdf) has been accepted by *The 36th Annual Conference on Neural Information Processing Systems (NeurIPS)*, Main Track, 2023.

Education
======
 - (B.Sc.) 2015.9-2019.6, School of computer science, Nanjing University of Information Science and Technology.
 - (M.Sc.) 2019.9-2022.4, College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Advisor: Prof. [Xiaoyang Tan](https://parnec.nuaa.edu.cn/xtan/).
 - (Ph.d. student) 2022.4-, College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Advisor: Prof. [Xiaoyang Tan](https://parnec.nuaa.edu.cn/xtan/).

Research Interests
======
 - (Robust & Generalizable & Safe & Offline) Reinforcement learning
 - Generative models for long-horizon planning
 - Cross-domain classification (Videos & Image)

Publications (†:Equal Contribution)
======
 - **†Jiang K**, †Jiang W, Tan X. Variational OOD State Correction for Offline Reinforcement Learning. *Annual AAAI Conference on Artificial Intelligence (AAAI)*, 2026, 40.[\[link\]](https://arxiv.org/abs/2505.00503)[\[code\]](https://github.com/Jack10843/DASP-master).
 - **Jiang K**, Jiang W, Li Y, Tan X. Beyond Non-Expert Demonstrations: Outcome-Driven Action Constraint for Offline Reinforcement Learning. *Pattern Recognition*, 2025.[\[link\]](https://authors.elsevier.com/a/1m5JS77nKsByF)[\[code\]](https://github.com/Jack10843/ODAF-master).
 - **Jiang K**, Li Y, Tan X. Towards Reliable Offline Reinforcement Learning via Lyapunov Uncertainty Control. *IEEE Transactions on Neural Networks and Learning Systems*, 2025.[\[link\]](https://doi.org/10.1109/TNNLS.2025.3616159)[\[code\]](https://github.com/Jack10843/LUC-master/)
 - Qiu L, **Jiang K**, Tan X. RoGA: Towards Generalizable Deepfake Detection through Robust Gradient Alignment. *IEEE International Conference on Multimedia & Expo (ICME)*, <span style="color:red">(Oral)</span>, 2025.[\[link\]](https://arxiv.org/abs/2505.20653)[\[code\]](https://github.com/Lynn0925/RoGA)
 - Qiu L, **Jiang K**, Tan X. Multi-level Distributional Discrepancy Enhancement for Cross Domain Face Forgery Detection. *Chinese Conference on Pattern Recognition and Computer Vision (PRCV)*, 2024, 508-522.
 - **Jiang K**, Yao J, Tan X. Recovering from out-of-sample states via inverse dynamics in offline reinforcement learning. *Advances in Neural Information Processing Systems (NeurIPS)*, 2023, 36.[\[link\]](https://proceedings.neurips.cc/paper_files/paper/2023/file/7a0f7e9d9b42b26e5bfc9ba4c6e5287c-Paper-Conference.pdf)[\[code\]](https://github.com/Jack10843/OSR)
 - Shen J, **Jiang K**, Tax X. Boundary Data Augmentation for Offline Reinforcement Learning. *ZTE Communications*, 2023, 21(3): 29.

Project Experiecne
======
 - A Research on Offline Reinforcement Learning Methods and Theories on Complex Real-world Scenarios (National Natural Science Foundation of China, No.6247072715, Leader: [Xiaoyang Tan](https://parnec.nuaa.edu.cn/xtan/)).

Preprints & Under Review (†:Equal Contribution)
======
 - †Wang Z, **†Jiang K**, Tan X. Calibrating Diffuser for Long-horizon Planning in Offline RL.
 - †Qiu L, **†Jiang K**, Tan X. [Contrastive Desensitization Learning for Cross Domain Face Forgery Detection](https://arxiv.org/abs/2505.20675).

Talks
======
 - Reliable Long-Horizon Planning Based on Diffusion Model for Offline Reinforcement Learning. (Jul, 2025, Personal Siminar, [Machine Learning & Systems Laboratory](https://mls.ist.osaka-u.ac.jp/en/member.html), Osaka University, Japan)
 - Application of Koopman Theory in Generalizable Offline Reinforcement Learning. (Jan, 2025, Personal Siminar, [Machine Learning & Systems Laboratory](https://mls.ist.osaka-u.ac.jp/en/member.html), Osaka University, Japan)
 - Offline reinforcement learning from non-expert data via state-supported boostrapping. (Nov, 2024, A3 Foresight Program, Beijing, China)

Fundings
======
 - April 2025 - October 2025, Short Visit Program, Nanjing University of Aeronautics and Astronautics (No.241206DF16).

Academic & Working Activities
======
 - Reviewer of international conferences, including NeurIPS, ICLR, AAAI, ICME.
 - Teaching Assistant of "Machine learning and its applications 2023" (by Professor Xiaoyang Tan) at Nanjing University of Aeronautics and Astronautics.

Hobbies
======
Fitness, Food, Traveling

